{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MkDocs \u00b6 For full documentation visit mkdocs.org . Commands \u00b6 mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message. Project layout \u00b6 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Home"},{"location":"#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"Mengukur Jarak Data (Penambangan Data)/","text":"Mengukur Jarak Data 1. Mengukur Jarak Tipe Numerik \u00b6 Ada beberapa ukuran similaritas data ukuran jarak, diantaranya: a) Minkowski Distance Kelompok Minkowski diantaranya adalah Euclidean distance dan Manhattan distance, Minkowski distance dinyatakan dengan: $$ \\begin{align} d _ { \\operatorname { min } } = ( \\ sum _ { i = 1 } ^ { n } | x _ { i } - y _ { i } | ^ { m } ) ^ { \\frac { 1 } { m } } , m \\geq 1 \\end{align} $$ b) Manhattan Distance Manhattan distance ialah kasus khusus dimana jarak dari minkoswski distance pada m= 1. Manhattan distance sensitif terhadap outlier. Jika ukuran ini digunakan dalam algoritma cleustering maka bentuk cleuster adalah hyper-rectangular. Ukuran ini dinyatakan dengan: $$ d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| $$ c) Euclidean Distance Euclidean distance ialah metode pengukuran yang paling sering digunakan, euclidean distance menghitung akar dari kuadrat perbedaan dua buah atau lebih vektor. Metode ini dapat digunakan untuk mendeteksi tingkat ketidaksamaan citra dengan cara mengisi nilai vektor p dan q dengan nilai fitur citra yang akan dideteksi tingkat ketidaksamaannya. Euclidean distance memiliki kelemahan yaitu jika dua vektor data tidak memiliki nilai atribut yang sama, kemungkinan memiliki jarak yang lebih kecil daripada pasangan vektro data lainnya yang mengandung nilai atribut yang sama. d) Average Distance Dikarenakan kekurangan dari jarak euclidian distance diatas, maka rata-rata jarak adalah versi modifikasi dari jarak euclidian distance untuk memperbaiki hasil. Rata-rata jarak didefinisikan dengan: $$ d _ { a v e } = \\left ( \\frac { 1 } { n } \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } \\right) ^ { \\frac { 1 } { 2 } } $$ e) Weighted Euclidean Distance Jika berdasarkan tingkat penting dari masing-masing atribut ditentukan, maka weihted euclidean distance adalah modifikasi lain dari jarak euclidean distance yang dapat digunakan. Ukuran ini didefinisikan dengan: $$ d _ { w e } = \\left ( \\sum _ { i = 1 } ^ { n } w _ { i } ( x _ { i } - y _ { i } \\right) ^ { 2 } ) ^ { \\frac { 1 } { 2 } } $$ f) Chord Distance Chord distance adalah salah satu ukuran modifikasi euclidean distance untuk mengatasi kekurangan dari euclidean distance. Jarak ini dapat juga dihitung dari data yang tidak dinormalisasi, Chord distance didefinisikan dengan: $$ d _ { w e } = \\left ( \\sum _ { i = 1 } ^ { n } w _ { i } ( x _ { i } - y _ { i } \\right) ^ { 2 } ) ^ { \\frac { 1 } { 2 } } $$ g) Mahalanobis Distance Jarak mahalanobis yang teratur dapat digunakan untuk mengekstaksi hyperellipsoidal clusters. Jarak mahanalobis dapat mengurangi distorsi yang disebabkan oleh korelasi linier antar fitur dengan menerapkan transformasi pemutihan ke data atau dengan menggunakan kuadrat jarak mahalanobis. Mahalanobis distance didefinisikan dengan: $$ d _ { m a h } = \\sqrt { ( x - y ) S ^ { - 1 } ( x - y ) ^ { T } } $$ h) Cosine Measure Ukuran cosine similarty lebih banyak digunakan dalam similaritas dokumen dan didefinisikan dengan: $$ Cosine(x,y)=\\frac { \\sum _ { i = 1 } ^ { n } x _ { i } y _ { i } } { | x | _ { 2 } | y | _ { 2 } } $$ i) Pearson Correlation Pearson correlation banyak digunakan pada data expresi gen. ukuran ini menghitung antara dua bentuk pola expresi gen. pearson corralatin didefinisikan dengan: $$ Pearson ( x , y ) = \\frac { \\sum _ { i = 1 } ^ { n } ( x _ { i } - \\mu _ { x } ) ( y _ { i } - \\mu _ { y } ) } { \\sqrt { \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } } \\sqrt { \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } } } $$ 2.Mengukur Jarak Atribut Binary \u00b6 Similaritas dan desimilirity untuk objek yang dijelaskan oleh atribut biner simetris atau asimetris. Aatribut biner hanya memiliki dua status: 0 dan 1 Contoh atribut perokok menggambarkan seorang pasien, misalnya, 1 menunjukkan bahwa pasien merokok, sedangkan 0 menunjukkan pasien tidak merokok. Memperlakukan atribut biner sebagai atribut numerik tidak diperkenankan. Oleh karena itu, metode khusus untuk data biner diperlukan untuk membedakan komputasi. Dissimilarity dan Similarity Rumus dissimilarity antara ii dan jj dan dinyatankan sebagai atribut biner simetris adalah: $$ \\begin{align} d(i,j) = \\frac {r+s}{q+r+s+t} \\end{align} $$ Rumus dissimilarity antara ii dan jj dan dinyatankan sebagai atribut biner asimetris adalah: $$ \\begin{align} d(i,j) = \\frac {r+s}{q+r+s} \\end{align} $$ Persamaan similarity Jaccard coefficient rumusnya adalah: $$ \\begin{align} sim(i,j) = \\frac {q}{q+r+s} = 1-d(i,j) \\end{align} $$ 3.Mengukur Jarak Menggunakan Catergorical \u00b6 Overlay Metric Untuk semua atribut bertipe nominal, ukuran jarak yang paling sederhana adalah Overlay Metric (OM) dinyatakan dengan $$ \\begin{align} d(x,y) = \\sum_{i=1}^n\\delta(a_i(x),a_i(y)) \\end{align} $$ Dimana nn adalah banyaknya atribut, ai(x)ai(x) dan ai(y)ai(y) adalah nilai atribut ke ii yaitu AiAi dari masing-masing objek xx dan yy, \u03b4(ai(x))(ai(y))\u03b4(ai(x))(ai(y)) adalah 0 jika ai(x)ai(x) = ai(y)ai(y) dan 1 jika sebaliknya. Value Difference Metri VDM dikenalkan oleh Standfill and Waltz, versi sederhana dari VDM tanpa skema pembobotan didefinsisikan dengan: $$ \\begin{align} d(x,y) = \\sum_{i=1}^n\\sum_{c=1}^C|P(c|a_i(x)) - P(c|a_i(y)) \\end{align} $$ Dimana CC adalah banyaknya kelas, P(c|ai(x))P(c|ai(x)) adalah probabilitas bersyarat dimana kelas xx adalah cc dari atribut AiAi, yang memilki nilai ai(x)ai(x), P(c|ai(y))P(c|ai(y)) adalah probabilitas bersyarat dimana kelas y adalah c dengan atribut AiAi memiliki nilai ai(y). Minimum Risk Metric Ukuran ini dipresentasikan oleh Blanzieri and Ricci, berbeda dari SFM yaitu meminimumkan selisih antara kesalahan berhingga dan kesalahan asymtotic. MRM meminimumkan risk of misclassification yang didefinisikan dengan: $$ \\begin{align} d(x,y) = \\sum_{c=1}^C|P(c|x) (1 - P(c|y)) \\end{align} $$ 4. Mengukur Jarak Tipe Ordinal \u00b6 Perlakuan untuk atribut ordinal adalah cukup sama dengan atribut numerik ketika menghitung disimilarity antara objek. Misalkan ff adalah atribut-atribut dari atribut ordinak dan nn objek. Menghitung disimilarity terhadap ff fitur sebagai berikut: - Nilai ff untuk objek ke-ii adalah xifxif, dan ff memiliki MfMf status urutan, mewakili peringkat 1,...,Mf1,...,Mf ganti setiap XifXif dengan peringkatnya rif\u22081...MMfrif\u22081...MMf Karena setiap atribut ordinal dapat memiliki jumlah state yang berbeda, diperlukan untuk memetakan rentang setiap atribut ke [0,0, 1.0] sehingga setiap atribut memiliki bobot yang sama. Perl melakukan normalisasi data dengan mengganti peringkat rifrif dengan $$ \\begin{align} z_{if} = \\frac{r_{if} - 1}{M_f - 1} \\end{align} $$ Dissimilarity kemudian dihitung dengan menggunakan ukuran jarak seperti atribut numerik dengan data yang baru setelah ditransformasi zif 5. Mengukur Jarak Tipe Campuran \u00b6 \\begin{align} d(i,j) = \\frac{\\sum_{f=1}^p\\delta_{ij}^{(f)} d_{ij}^{(f)}}{\\sum_{f=1}^pd_{ij}^{(f)}} \\end{align} \\begin{align} d(i,j) = \\frac{\\sum_{f=1}^p\\delta_{ij}^{(f)} d_{ij}^{(f)}}{\\sum_{f=1}^pd_{ij}^{(f)}} \\end{align} import pandas as pd from scipy import stats import numpy as np import seaborn as sns import matplotlib.pyplot as plt data = pd . read_csv ( \"Abalone.csv\" , delimiter = \";\" ) k = data . iloc [ 0 : 18 ] def jarak ( v1 , v2 ): return (( chordDist ( v1 , v2 , numerical ) + ordDist ( v1 , v2 , ordinal ) + categoricalDist ( v1 , v2 , categorical ) + binaryDist ( v1 , v2 , binary )) / 4 ) from IPython.display import HTML , display import tabulate table = [ [ \"Data\" ] + [ \"Jarak\" ] + [ \"Numeric\" ] + [ \"Ordinal\" ] + [ \"Categorical\" ] + [ \"Binary\" ], [ \"v1-v2\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 0 , 1 , numerical ))] + [ \"{:.2f}\" . format ( ordDist ( 0 , 1 , ordinal ))] + [ categoricalDist ( 0 , 1 , categorical )] + [ binaryDist ( 0 , 1 , binary )], [ \"v1-v3\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 0 , 2 , numerical ))] + [ \"{:.2f}\" . format ( ordDist ( 0 , 2 , ordinal ))] + [ categoricalDist ( 0 , 2 , categorical )] + [ binaryDist ( 0 , 1 , binary )], [ \"v2-v3\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 1 , 2 , numerical ))] + [ \"{:.2f}\" . format ( ordDist ( 1 , 2 , ordinal ))] + [ categoricalDist ( 1 , 2 , categorical )] + [ binaryDist ( 0 , 1 , binary )], [ \"v3-v4\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 2 , 3 , numerical ))] + [ \"{:.2f}\" . format ( ordDist ( 2 , 3 , ordinal ))] + [ categoricalDist ( 2 , 3 , categorical )] + [ binaryDist ( 0 , 1 , binary )], [ \"v4-v5\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 3 , 4 , numerical ))] + [ \"{:.2f}\" . format ( ordDist ( 3 , 4 , ordinal ))] + [ categoricalDist ( 3 , 4 , categorical )] + [ binaryDist ( 0 , 1 , binary )], [ \"v5-v6\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 4 , 5 , numerical ))] + [ \"{:.2f}\" . format ( ordDist ( 4 , 5 , ordinal ))] + [ categoricalDist ( 4 , 5 , categorical )] + [ binaryDist ( 0 , 1 , binary )], ] display ( HTML ( tabulate . tabulate ( table , tablefmt = 'html' )))","title":"Menghitung Jarak Data"},{"location":"Mengukur Jarak Data (Penambangan Data)/#1-mengukur-jarak-tipe-numerik","text":"Ada beberapa ukuran similaritas data ukuran jarak, diantaranya: a) Minkowski Distance Kelompok Minkowski diantaranya adalah Euclidean distance dan Manhattan distance, Minkowski distance dinyatakan dengan: $$ \\begin{align} d _ { \\operatorname { min } } = ( \\ sum _ { i = 1 } ^ { n } | x _ { i } - y _ { i } | ^ { m } ) ^ { \\frac { 1 } { m } } , m \\geq 1 \\end{align} $$ b) Manhattan Distance Manhattan distance ialah kasus khusus dimana jarak dari minkoswski distance pada m= 1. Manhattan distance sensitif terhadap outlier. Jika ukuran ini digunakan dalam algoritma cleustering maka bentuk cleuster adalah hyper-rectangular. Ukuran ini dinyatakan dengan: $$ d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| $$ c) Euclidean Distance Euclidean distance ialah metode pengukuran yang paling sering digunakan, euclidean distance menghitung akar dari kuadrat perbedaan dua buah atau lebih vektor. Metode ini dapat digunakan untuk mendeteksi tingkat ketidaksamaan citra dengan cara mengisi nilai vektor p dan q dengan nilai fitur citra yang akan dideteksi tingkat ketidaksamaannya. Euclidean distance memiliki kelemahan yaitu jika dua vektor data tidak memiliki nilai atribut yang sama, kemungkinan memiliki jarak yang lebih kecil daripada pasangan vektro data lainnya yang mengandung nilai atribut yang sama. d) Average Distance Dikarenakan kekurangan dari jarak euclidian distance diatas, maka rata-rata jarak adalah versi modifikasi dari jarak euclidian distance untuk memperbaiki hasil. Rata-rata jarak didefinisikan dengan: $$ d _ { a v e } = \\left ( \\frac { 1 } { n } \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } \\right) ^ { \\frac { 1 } { 2 } } $$ e) Weighted Euclidean Distance Jika berdasarkan tingkat penting dari masing-masing atribut ditentukan, maka weihted euclidean distance adalah modifikasi lain dari jarak euclidean distance yang dapat digunakan. Ukuran ini didefinisikan dengan: $$ d _ { w e } = \\left ( \\sum _ { i = 1 } ^ { n } w _ { i } ( x _ { i } - y _ { i } \\right) ^ { 2 } ) ^ { \\frac { 1 } { 2 } } $$ f) Chord Distance Chord distance adalah salah satu ukuran modifikasi euclidean distance untuk mengatasi kekurangan dari euclidean distance. Jarak ini dapat juga dihitung dari data yang tidak dinormalisasi, Chord distance didefinisikan dengan: $$ d _ { w e } = \\left ( \\sum _ { i = 1 } ^ { n } w _ { i } ( x _ { i } - y _ { i } \\right) ^ { 2 } ) ^ { \\frac { 1 } { 2 } } $$ g) Mahalanobis Distance Jarak mahalanobis yang teratur dapat digunakan untuk mengekstaksi hyperellipsoidal clusters. Jarak mahanalobis dapat mengurangi distorsi yang disebabkan oleh korelasi linier antar fitur dengan menerapkan transformasi pemutihan ke data atau dengan menggunakan kuadrat jarak mahalanobis. Mahalanobis distance didefinisikan dengan: $$ d _ { m a h } = \\sqrt { ( x - y ) S ^ { - 1 } ( x - y ) ^ { T } } $$ h) Cosine Measure Ukuran cosine similarty lebih banyak digunakan dalam similaritas dokumen dan didefinisikan dengan: $$ Cosine(x,y)=\\frac { \\sum _ { i = 1 } ^ { n } x _ { i } y _ { i } } { | x | _ { 2 } | y | _ { 2 } } $$ i) Pearson Correlation Pearson correlation banyak digunakan pada data expresi gen. ukuran ini menghitung antara dua bentuk pola expresi gen. pearson corralatin didefinisikan dengan: $$ Pearson ( x , y ) = \\frac { \\sum _ { i = 1 } ^ { n } ( x _ { i } - \\mu _ { x } ) ( y _ { i } - \\mu _ { y } ) } { \\sqrt { \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } } \\sqrt { \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } } } $$","title":"1. Mengukur Jarak Tipe Numerik"},{"location":"Mengukur Jarak Data (Penambangan Data)/#2mengukur-jarak-atribut-binary","text":"Similaritas dan desimilirity untuk objek yang dijelaskan oleh atribut biner simetris atau asimetris. Aatribut biner hanya memiliki dua status: 0 dan 1 Contoh atribut perokok menggambarkan seorang pasien, misalnya, 1 menunjukkan bahwa pasien merokok, sedangkan 0 menunjukkan pasien tidak merokok. Memperlakukan atribut biner sebagai atribut numerik tidak diperkenankan. Oleh karena itu, metode khusus untuk data biner diperlukan untuk membedakan komputasi. Dissimilarity dan Similarity Rumus dissimilarity antara ii dan jj dan dinyatankan sebagai atribut biner simetris adalah: $$ \\begin{align} d(i,j) = \\frac {r+s}{q+r+s+t} \\end{align} $$ Rumus dissimilarity antara ii dan jj dan dinyatankan sebagai atribut biner asimetris adalah: $$ \\begin{align} d(i,j) = \\frac {r+s}{q+r+s} \\end{align} $$ Persamaan similarity Jaccard coefficient rumusnya adalah: $$ \\begin{align} sim(i,j) = \\frac {q}{q+r+s} = 1-d(i,j) \\end{align} $$","title":"2.Mengukur Jarak Atribut Binary"},{"location":"Mengukur Jarak Data (Penambangan Data)/#3mengukur-jarak-menggunakan-catergorical","text":"Overlay Metric Untuk semua atribut bertipe nominal, ukuran jarak yang paling sederhana adalah Overlay Metric (OM) dinyatakan dengan $$ \\begin{align} d(x,y) = \\sum_{i=1}^n\\delta(a_i(x),a_i(y)) \\end{align} $$ Dimana nn adalah banyaknya atribut, ai(x)ai(x) dan ai(y)ai(y) adalah nilai atribut ke ii yaitu AiAi dari masing-masing objek xx dan yy, \u03b4(ai(x))(ai(y))\u03b4(ai(x))(ai(y)) adalah 0 jika ai(x)ai(x) = ai(y)ai(y) dan 1 jika sebaliknya. Value Difference Metri VDM dikenalkan oleh Standfill and Waltz, versi sederhana dari VDM tanpa skema pembobotan didefinsisikan dengan: $$ \\begin{align} d(x,y) = \\sum_{i=1}^n\\sum_{c=1}^C|P(c|a_i(x)) - P(c|a_i(y)) \\end{align} $$ Dimana CC adalah banyaknya kelas, P(c|ai(x))P(c|ai(x)) adalah probabilitas bersyarat dimana kelas xx adalah cc dari atribut AiAi, yang memilki nilai ai(x)ai(x), P(c|ai(y))P(c|ai(y)) adalah probabilitas bersyarat dimana kelas y adalah c dengan atribut AiAi memiliki nilai ai(y). Minimum Risk Metric Ukuran ini dipresentasikan oleh Blanzieri and Ricci, berbeda dari SFM yaitu meminimumkan selisih antara kesalahan berhingga dan kesalahan asymtotic. MRM meminimumkan risk of misclassification yang didefinisikan dengan: $$ \\begin{align} d(x,y) = \\sum_{c=1}^C|P(c|x) (1 - P(c|y)) \\end{align} $$","title":"3.Mengukur Jarak Menggunakan Catergorical"},{"location":"Mengukur Jarak Data (Penambangan Data)/#4-mengukur-jarak-tipe-ordinal","text":"Perlakuan untuk atribut ordinal adalah cukup sama dengan atribut numerik ketika menghitung disimilarity antara objek. Misalkan ff adalah atribut-atribut dari atribut ordinak dan nn objek. Menghitung disimilarity terhadap ff fitur sebagai berikut: - Nilai ff untuk objek ke-ii adalah xifxif, dan ff memiliki MfMf status urutan, mewakili peringkat 1,...,Mf1,...,Mf ganti setiap XifXif dengan peringkatnya rif\u22081...MMfrif\u22081...MMf Karena setiap atribut ordinal dapat memiliki jumlah state yang berbeda, diperlukan untuk memetakan rentang setiap atribut ke [0,0, 1.0] sehingga setiap atribut memiliki bobot yang sama. Perl melakukan normalisasi data dengan mengganti peringkat rifrif dengan $$ \\begin{align} z_{if} = \\frac{r_{if} - 1}{M_f - 1} \\end{align} $$ Dissimilarity kemudian dihitung dengan menggunakan ukuran jarak seperti atribut numerik dengan data yang baru setelah ditransformasi zif","title":"4. Mengukur Jarak Tipe Ordinal"},{"location":"Mengukur Jarak Data (Penambangan Data)/#5-mengukur-jarak-tipe-campuran","text":"\\begin{align} d(i,j) = \\frac{\\sum_{f=1}^p\\delta_{ij}^{(f)} d_{ij}^{(f)}}{\\sum_{f=1}^pd_{ij}^{(f)}} \\end{align} \\begin{align} d(i,j) = \\frac{\\sum_{f=1}^p\\delta_{ij}^{(f)} d_{ij}^{(f)}}{\\sum_{f=1}^pd_{ij}^{(f)}} \\end{align} import pandas as pd from scipy import stats import numpy as np import seaborn as sns import matplotlib.pyplot as plt data = pd . read_csv ( \"Abalone.csv\" , delimiter = \";\" ) k = data . iloc [ 0 : 18 ] def jarak ( v1 , v2 ): return (( chordDist ( v1 , v2 , numerical ) + ordDist ( v1 , v2 , ordinal ) + categoricalDist ( v1 , v2 , categorical ) + binaryDist ( v1 , v2 , binary )) / 4 ) from IPython.display import HTML , display import tabulate table = [ [ \"Data\" ] + [ \"Jarak\" ] + [ \"Numeric\" ] + [ \"Ordinal\" ] + [ \"Categorical\" ] + [ \"Binary\" ], [ \"v1-v2\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 0 , 1 , numerical ))] + [ \"{:.2f}\" . format ( ordDist ( 0 , 1 , ordinal ))] + [ categoricalDist ( 0 , 1 , categorical )] + [ binaryDist ( 0 , 1 , binary )], [ \"v1-v3\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 0 , 2 , numerical ))] + [ \"{:.2f}\" . format ( ordDist ( 0 , 2 , ordinal ))] + [ categoricalDist ( 0 , 2 , categorical )] + [ binaryDist ( 0 , 1 , binary )], [ \"v2-v3\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 1 , 2 , numerical ))] + [ \"{:.2f}\" . format ( ordDist ( 1 , 2 , ordinal ))] + [ categoricalDist ( 1 , 2 , categorical )] + [ binaryDist ( 0 , 1 , binary )], [ \"v3-v4\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 2 , 3 , numerical ))] + [ \"{:.2f}\" . format ( ordDist ( 2 , 3 , ordinal ))] + [ categoricalDist ( 2 , 3 , categorical )] + [ binaryDist ( 0 , 1 , binary )], [ \"v4-v5\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 3 , 4 , numerical ))] + [ \"{:.2f}\" . format ( ordDist ( 3 , 4 , ordinal ))] + [ categoricalDist ( 3 , 4 , categorical )] + [ binaryDist ( 0 , 1 , binary )], [ \"v5-v6\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 4 , 5 , numerical ))] + [ \"{:.2f}\" . format ( ordDist ( 4 , 5 , ordinal ))] + [ categoricalDist ( 4 , 5 , categorical )] + [ binaryDist ( 0 , 1 , binary )], ] display ( HTML ( tabulate . tabulate ( table , tablefmt = 'html' )))","title":"5. Mengukur Jarak Tipe Campuran"},{"location":"Pengertian (Andi)/","text":"1. Mean(Rata-rata) \u00b6 Pengertian mean adalah nilai rata-rata dari beberapa buah data. Nilai mean dapat ditentukan dengan cara membagi jumlah data dengan banyaknya data. Rumus untuk mencari mean seperti berikut: $$ \\overline{x}=\\frac{\\sum_{i=1}^{N} x_{i}}{N}=\\frac{x_{1}+x_{2}+\\cdots+x_{N}}{N} $$ 2. Median \u00b6 pengertian median adalah suatu cara untuk menentukan letak tengah sebuah data setelah data disusun menurut urutan nilainya. Rumus untuk mencari median seperti berikut: M e=x_{i j}+\\left(\\frac{\\frac{n}{2}-f_{k i j}}{f_{i}}\\right) p M e=x_{i j}+\\left(\\frac{\\frac{n}{2}-f_{k i j}}{f_{i}}\\right) p 3. Modus \u00b6 Pengertian modus adalah nilai yang sering muncul. Untuk ingin melihat suatu hasil akhir dari modus maka harus menentukan kelas pada tabel dengan memilih frekuensi yang paling banyak. Rumus untuk mencari modus seperti berikut: \\text { mean }-\\text { mode } \\approx 3 \\times(\\text { mean }-\\text { median }) \\text { mean }-\\text { mode } \\approx 3 \\times(\\text { mean }-\\text { median }) 4. Standard deviasi \u00b6 Pengertian standard deviasi adalah nilai statistik yang digunakan untuk menentukan bagaimana sebaran data dalam sampel, dan seberapa dekat titik data individu ke mean atau rata-rata nilai sampel. Rumus untuk mencari standard deviasi sebagai berikut: \\sigma ^ { 2 } = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } ( x _ { i } - \\overline { x } ) ^ { 2 } = ( \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \\overline { x } ^ { 2 } \\sigma ^ { 2 } = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } ( x _ { i } - \\overline { x } ) ^ { 2 } = ( \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \\overline { x } ^ { 2 } 5. Varian \u00b6 Pengertian varian adalah ukuran seberapa jauh sebuah kumpulan bilangan tersebar, varian juga merupakan salah satu pendeskripsi dari sebuah distribusi probabilitas. Rumus untuk mencari devian sebagai berikut: \\sigma = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } ( x _ { i } - \\overline { x } ) ^ { 2 } = ( \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \\overline { x } ^ { 2 } \\sigma = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } ( x _ { i } - \\overline { x } ) ^ { 2 } = ( \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \\overline { x } ^ { 2 } 6. Skewness (Kemiringan) \u00b6 Pngertian skewness adalah derajat ketidaksimetrisan atau distribusi. Rumus untuk mencari skewness sebagai berikut: s k=\\frac{\\overline{X}-M o}{s} s k=\\frac{\\overline{X}-M o}{s} 7.Kuartil \u00b6 Pengertian kuartil adalah nilai-nilai yang membagi data yang telah diurutkan kedalam empat bagian yang nilainya sama besar, Kuartil terbagi menjadi 3 macam antara lain: a) Kuartil bawah (k1) b) kuartil tengah (k2) c)) Kuartil atas (k3) Rumus untuk memcri kuartil 1,2, dan 3 sebagai berikut: IQR=Q3\u2212Q1 IQR=Q3\u2212Q1 import pandas as pd from scipy import stats import numpy as np import seaborn as sns import matplotlib as plt data = pd . read_csv ( \"ANDIAJADOANG.csv\" , delimiter = \";\" ) cm = sns . light_palette ( \"gold\" , as_cmap = True ) data . style . background_gradient ( cmap = cm ) colum = data . columns . tolist () for x in colum : ds = [ x for x in data [ x ]] desc = data [ x ] . describe () array = [ x for x in desc ] print ( \"Detail kolom\" , x ) print ( \"rata-rata: \" , array [ 1 ]) print ( \"Median: \" , np . median ( np . array ( ds ))) print ( \"Modus: \" , stats . mode ( ds )) print ( \"Standard deviasi: \" , np . std ( ds )) print ( \"varian: \" , stats . variation ( ds )) print ( \"Skewness: \" , stats . skew ( ds )) print ( \"Quartil 1: \" , array [ 4 ]) print ( \"Quartil 2: \" , array [ 5 ]) print ( \"Quartil 3: \" , array [ 6 ]) sns . distplot ( data [ x ]) \u200b","title":"Statistika"},{"location":"Pengertian (Andi)/#1-meanrata-rata","text":"Pengertian mean adalah nilai rata-rata dari beberapa buah data. Nilai mean dapat ditentukan dengan cara membagi jumlah data dengan banyaknya data. Rumus untuk mencari mean seperti berikut: $$ \\overline{x}=\\frac{\\sum_{i=1}^{N} x_{i}}{N}=\\frac{x_{1}+x_{2}+\\cdots+x_{N}}{N} $$","title":"1. Mean(Rata-rata)"},{"location":"Pengertian (Andi)/#2-median","text":"pengertian median adalah suatu cara untuk menentukan letak tengah sebuah data setelah data disusun menurut urutan nilainya. Rumus untuk mencari median seperti berikut: M e=x_{i j}+\\left(\\frac{\\frac{n}{2}-f_{k i j}}{f_{i}}\\right) p M e=x_{i j}+\\left(\\frac{\\frac{n}{2}-f_{k i j}}{f_{i}}\\right) p","title":"2. Median"},{"location":"Pengertian (Andi)/#3-modus","text":"Pengertian modus adalah nilai yang sering muncul. Untuk ingin melihat suatu hasil akhir dari modus maka harus menentukan kelas pada tabel dengan memilih frekuensi yang paling banyak. Rumus untuk mencari modus seperti berikut: \\text { mean }-\\text { mode } \\approx 3 \\times(\\text { mean }-\\text { median }) \\text { mean }-\\text { mode } \\approx 3 \\times(\\text { mean }-\\text { median })","title":"3. Modus"},{"location":"Pengertian (Andi)/#4-standard-deviasi","text":"Pengertian standard deviasi adalah nilai statistik yang digunakan untuk menentukan bagaimana sebaran data dalam sampel, dan seberapa dekat titik data individu ke mean atau rata-rata nilai sampel. Rumus untuk mencari standard deviasi sebagai berikut: \\sigma ^ { 2 } = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } ( x _ { i } - \\overline { x } ) ^ { 2 } = ( \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \\overline { x } ^ { 2 } \\sigma ^ { 2 } = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } ( x _ { i } - \\overline { x } ) ^ { 2 } = ( \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \\overline { x } ^ { 2 }","title":"4. Standard deviasi"},{"location":"Pengertian (Andi)/#5-varian","text":"Pengertian varian adalah ukuran seberapa jauh sebuah kumpulan bilangan tersebar, varian juga merupakan salah satu pendeskripsi dari sebuah distribusi probabilitas. Rumus untuk mencari devian sebagai berikut: \\sigma = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } ( x _ { i } - \\overline { x } ) ^ { 2 } = ( \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \\overline { x } ^ { 2 } \\sigma = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } ( x _ { i } - \\overline { x } ) ^ { 2 } = ( \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \\overline { x } ^ { 2 }","title":"5. Varian"},{"location":"Pengertian (Andi)/#6-skewness-kemiringan","text":"Pngertian skewness adalah derajat ketidaksimetrisan atau distribusi. Rumus untuk mencari skewness sebagai berikut: s k=\\frac{\\overline{X}-M o}{s} s k=\\frac{\\overline{X}-M o}{s}","title":"6. Skewness (Kemiringan)"},{"location":"Pengertian (Andi)/#7kuartil","text":"Pengertian kuartil adalah nilai-nilai yang membagi data yang telah diurutkan kedalam empat bagian yang nilainya sama besar, Kuartil terbagi menjadi 3 macam antara lain: a) Kuartil bawah (k1) b) kuartil tengah (k2) c)) Kuartil atas (k3) Rumus untuk memcri kuartil 1,2, dan 3 sebagai berikut: IQR=Q3\u2212Q1 IQR=Q3\u2212Q1 import pandas as pd from scipy import stats import numpy as np import seaborn as sns import matplotlib as plt data = pd . read_csv ( \"ANDIAJADOANG.csv\" , delimiter = \";\" ) cm = sns . light_palette ( \"gold\" , as_cmap = True ) data . style . background_gradient ( cmap = cm ) colum = data . columns . tolist () for x in colum : ds = [ x for x in data [ x ]] desc = data [ x ] . describe () array = [ x for x in desc ] print ( \"Detail kolom\" , x ) print ( \"rata-rata: \" , array [ 1 ]) print ( \"Median: \" , np . median ( np . array ( ds ))) print ( \"Modus: \" , stats . mode ( ds )) print ( \"Standard deviasi: \" , np . std ( ds )) print ( \"varian: \" , stats . variation ( ds )) print ( \"Skewness: \" , stats . skew ( ds )) print ( \"Quartil 1: \" , array [ 4 ]) print ( \"Quartil 2: \" , array [ 5 ]) print ( \"Quartil 3: \" , array [ 6 ]) sns . distplot ( data [ x ]) \u200b","title":"7.Kuartil"}]}