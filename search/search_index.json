{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Selamat Datang Di Halaman Web A. Fadilah Aini \u00b6 Profil Singkat \u00b6 Nama : A.Fadilah Aini NIM : 18041110014 Kelas : Penambangan Data 5C Dosen Pengampuh : Mulaab, S.Si, M.Kom Program Studi : Teknik Informatika","title":"Home"},{"location":"#selamat-datang-di-halaman-web-a-fadilah-aini","text":"","title":"Selamat Datang Di Halaman Web A. Fadilah Aini"},{"location":"#profil-singkat","text":"Nama : A.Fadilah Aini NIM : 18041110014 Kelas : Penambangan Data 5C Dosen Pengampuh : Mulaab, S.Si, M.Kom Program Studi : Teknik Informatika","title":"Profil Singkat"},{"location":"Mengukur%20Jarak%20Data%20%28Penambangan%20Data%29/","text":"1. Mengukur Jarak Tipe Numerik \u00b6 Ada beberapa ukuran similaritas data ukuran jarak, diantaranya: a) Minkowski Distance \u00b6 Kelompok Minkowski diantaranya adalah Euclidean distance dan Manhattan distance, Minkowski distance dinyatakan dengan: $$ \\begin{align} d _ { \\operatorname { min } } = ( \\sum _ { i = 1 } ^ { n } | x _ { i } - y _ { i } | ^ { m } ) ^ { \\frac { 1 } { m } } , m \\geq 1 \\end{align} $$ b) Manhattan Distance \u00b6 Manhattan distance ialah kasus khusus dimana jarak dari minkoswski distance pada m= 1. Manhattan distance sensitif terhadap outlier. Jika ukuran ini digunakan dalam algoritma cleustering maka bentuk cleuster adalah hyper-rectangular. Ukuran ini dinyatakan dengan: $$ d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| $$ c) Euclidean Distance \u00b6 Euclidean distance ialah metode pengukuran yang paling sering digunakan, euclidean distance menghitung akar dari kuadrat perbedaan dua buah atau lebih vektor. Metode ini dapat digunakan untuk mendeteksi tingkat ketidaksamaan citra dengan cara mengisi nilai vektor p dan q dengan nilai fitur citra yang akan dideteksi tingkat ketidaksamaannya. Euclidean distance memiliki kelemahan yaitu jika dua vektor data tidak memiliki nilai atribut yang sama, kemungkinan memiliki jarak yang lebih kecil daripada pasangan vektro data lainnya yang mengandung nilai atribut yang sama. d) Average Distance \u00b6 Dikarenakan kekurangan dari jarak euclidian distance diatas, maka rata-rata jarak adalah versi modifikasi dari jarak euclidian distance untuk memperbaiki hasil. Rata-rata jarak didefinisikan dengan: $$ d _ { a v e } = \\left ( \\frac { 1 } { n } \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } \\right) ^ { \\frac { 1 } { 2 } } $$ e) Weighted Euclidean Distance \u00b6 Jika berdasarkan tingkat penting dari masing-masing atribut ditentukan, maka weihted euclidean distance adalah modifikasi lain dari jarak euclidean distance yang dapat digunakan. Ukuran ini didefinisikan dengan: $$ d _ { w e } = \\left ( \\sum _ { i = 1 } ^ { n } w _ { i } ( x _ { i } - y _ { i } \\right) ^ { 2 } ) ^ { \\frac { 1 } { 2 } } $$ f) Chord Distance \u00b6 Chord distance adalah salah satu ukuran modifikasi euclidean distance untuk mengatasi kekurangan dari euclidean distance. Jarak ini dapat juga dihitung dari data yang tidak dinormalisasi, Chord distance didefinisikan dengan: $$ d _ { w e } = \\left ( \\sum _ { i = 1 } ^ { n } w _ { i } ( x _ { i } - y _ { i } \\right) ^ { 2 } ) ^ { \\frac { 1 } { 2 } } $$ g) Mahalanobis Distance \u00b6 Jarak mahalanobis yang teratur dapat digunakan untuk mengekstaksi hyperellipsoidal clusters. Jarak mahanalobis dapat mengurangi distorsi yang disebabkan oleh korelasi linier antar fitur dengan menerapkan transformasi pemutihan ke data atau dengan menggunakan kuadrat jarak mahalanobis. Mahalanobis distance didefinisikan dengan: $$ d _ { m a h } = \\sqrt { ( x - y ) S ^ { - 1 } ( x - y ) ^ { T } } $$ h) Cosine Measure \u00b6 Ukuran cosine similarty lebih banyak digunakan dalam similaritas dokumen dan didefinisikan dengan: $$ Cosine(x,y)=\\frac { \\sum _ { i = 1 } ^ { n } x _ { i } y _ { i } } { | x | _ { 2 } | y | _ { 2 } } $$ i) Pearson Correlation \u00b6 Pearson correlation banyak digunakan pada data expresi gen. ukuran ini menghitung antara dua bentuk pola expresi gen. pearson corralatin didefinisikan dengan: $$ Pearson ( x , y ) = \\frac { \\sum _ { i = 1 } ^ { n } ( x _ { i } - \\mu _ { x } ) ( y _ { i } - \\mu _ { y } ) } { \\sqrt { \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } } \\sqrt { \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } } } $$ 2.Mengukur Jarak Atribut Binary \u00b6 Similaritas dan desimilirity untuk objek yang dijelaskan oleh atribut biner simetris atau asimetris. Aatribut biner hanya memiliki dua status: 0 dan 1 Contoh atribut perokok menggambarkan seorang pasien, misalnya, 1 menunju kkan bahwa pasien merokok, sedangkan 0 menunjukkan pasien tidak merokok. Memperlakukan atribut biner sebagai atribut numerik tidak diperkennkan. Oleh karena itu,metode khusus untuk data biner diperlukan untuk membedakan komputasi. Dissimilarity dan Similarity \u00b6 Rumus dissimilarity antara ii dan jj dan dinyatankan sebagai atribut biner simetris adalah: $$ \\begin{align} d(i,j) = \\frac {r+s}{q+r+s+t} \\end{align} $$ Rumusmedunissimilarity antara ii d n jj dan dinyatankan sebagai atribut binimetris adalah: $$ \\begin{align} d(i,j) = \\frac {r+s}{q+r+s} \\end{align} $$ Persamaan similarity Jaccard coefficient rumusnya adalah: $$ \\begin{align} sim(i,j) = \\frac {q}{q+r+s} = 1-d(i,j) \\end{align} $$ 3.Mengukur Jarak Menggunakan Catergorical \u00b6 1. Overlay Metric \u00b6 Untuk semua atribut bertipe nominal, ukuran jarak yang paling sederhana adalah Overlay Metric (OM) dinyatakan dengan $$ \\begin{align} d(x,y) = \\sum_{i=1}^n\\delta(a_i(x),a_i(y)) \\end{align} $$ Dimana nn adalah banyaknya atribut, ai(x)ai(x) dan ai(y)ai(y) adalah nilai atribut ke ii yaitu AiAi dari masing-masing objek xx dan yy, \u03b4(ai(x))(ai(y))\u03b4(ai(x))(ai(y)) adalah 0 jika ai(x)ai(x) = ai(y)ai(y) dan 1 jika sebaliknya. 2. Value Difference Metri \u00b6 VDM dikenalkan oleh Standfill and Waltz, versi sederhana dari VDM tanpa skema pembobotan didefinsisikan dengan: $$ \\begin{align} d(x,y) = \\sum_{i=1}^n\\sum_{c=1}^C|P(c|a_i(x)) - P(c|a_i(y)) \\end{align} $$ Dimana CC adalah banyaknya kelas, P(c|ai(x))P(c|ai(x)) adalah probabilitas bersyarat dimana kelas xx adalah cc dari atribut AiAi, yang memilki nilai ai(x)ai(x), P(c|ai(y))P(c|ai(y)) adalah probabilitas bersyarat dimana kelas y adalah c dengan atribut AiAi memiliki nilai ai(y). 3. Minimum Risk Metric \u00b6 Ukuran ini dipresentasikan oleh Blanzieri and Ricci, berbeda dari SFM yaitu meminimumkan selisih antara kesalahan berhingga dan kesalahan asymtotic. MRM meminimumkan risk of misclassification yang didefinisikan dengan: $$ \\begin{align} d(x,y) = \\sum_{c=1}^C|P(c|x) (1 - P(c|y)) \\end{align} $$ 4. Mengukur Jarak Tipe Ordinal \u00b6 Perlakuan untuk atribut ordinal adalah cukup sama dengan atribut numerik ketika menghitung disimilarity antara objek. Misalkan ff adalah atribut-atribut dari atribut ordinak dan nn objek. Menghitung disimilarity terhadap ff fitur sebagai berikut: - Nilai ff untuk objek ke-ii adalah xifxif, dan ff memiliki MfMf status urutan, mewakili peringkat 1,...,Mf1,...,Mf ganti setiap XifXif dengan peringkatnya rif\u22081...MMfrif\u22081...MMf Karena setiap atribut ordinal dapat memiliki jumlah state yang berbeda, diperlukan untuk memetakan rentang setiap atribut ke [0,0, 1.0] sehingga setiap atribut memiliki bobot yang sama. Perl melakukan normalisasi data dengan mengganti peringkat rifrif dengan $$ \\begin{align} z_{if} = \\frac{r_{if} - 1}{M_f - 1} \\end{align} $$ Dissimilarity kemudian dihitung dengan menggunakan ukuran jarak seperti atribut numerik dengan data yang baru setelah ditransformasi zif 5. Mengukur Jarak Tipe Campuran \u00b6 \\begin{align} d(i,j) = \\frac{\\sum_{f=1}^p\\delta_{ij}^{(f)} d_{ij}^{(f)}}{\\sum_{f=1}^pd_{ij}^{(f)}} \\end{align} \\begin{align} d(i,j) = \\frac{\\sum_{f=1}^p\\delta_{ij}^{(f)} d_{ij}^{(f)}}{\\sum_{f=1}^pd_{ij}^{(f)}} \\end{align} import pandas as pd from scipy import stats import numpy as np import seaborn as sns import matplotlib.pyplot as plt data = pd . read_csv ( \"Abalone.csv\" , delimiter = \";\" ) k = data . iloc [ 0 : 18 ] def jarak ( v1 , v2 ): return (( chordDist ( v1 , v2 , numerical ) + ordDist ( v1 , v2 , ordinal ) + categoricalDist ( v1 , v2 , categorical ) + binaryDist ( v1 , v2 , binary )) / 4 ) from IPython.display import HTML , display import tabulate table = [ [ \"Data\" ] + [ \"Jarak\" ] + [ \"Numeric\" ] + [ \"Ordinal\" ] + [ \"Categorical\" ] + [ \"Binary\" ], [ \"v1-v2\" ] + [ 0 ] + [ \" {:.2f} \" . format ( chordDist ( 0 , 1 , numerical ))] + [ \" {:.2f} \" . format ( ordDist ( 0 , 1 , ordinal ))] + [ categoricalDist ( 0 , 1 , categorical )] + [ binaryDist ( 0 , 1 , binary )], [ \"v1-v3\" ] + [ 0 ] + [ \" {:.2f} \" . format ( chordDist ( 0 , 2 , numerical ))] + [ \" {:.2f} \" . format ( ordDist ( 0 , 2 , ordinal ))] + [ categoricalDist ( 0 , 2 , categorical )] + [ binaryDist ( 0 , 1 , binary )], [ \"v2-v3\" ] + [ 0 ] + [ \" {:.2f} \" . format ( chordDist ( 1 , 2 , numerical ))] + [ \" {:.2f} \" . format ( ordDist ( 1 , 2 , ordinal ))] + [ categoricalDist ( 1 , 2 , categorical )] + [ binaryDist ( 0 , 1 , binary )], [ \"v3-v4\" ] + [ 0 ] + [ \" {:.2f} \" . format ( chordDist ( 2 , 3 , numerical ))] + [ \" {:.2f} \" . format ( ordDist ( 2 , 3 , ordinal ))] + [ categoricalDist ( 2 , 3 , categorical )] + [ binaryDist ( 0 , 1 , binary )], [ \"v4-v5\" ] + [ 0 ] + [ \" {:.2f} \" . format ( chordDist ( 3 , 4 , numerical ))] + [ \" {:.2f} \" . format ( ordDist ( 3 , 4 , ordinal ))] + [ categoricalDist ( 3 , 4 , categorical )] + [ binaryDist ( 0 , 1 , binary )], [ \"v5-v6\" ] + [ 0 ] + [ \" {:.2f} \" . format ( chordDist ( 4 , 5 , numerical ))] + [ \" {:.2f} \" . format ( ordDist ( 4 , 5 , ordinal ))] + [ categoricalDist ( 4 , 5 , categorical )] + [ binaryDist ( 0 , 1 , binary )], ] display ( HTML ( tabulate . tabulate ( table , tablefmt = 'html' )))","title":"Menghitung Jarak Data"},{"location":"Mengukur%20Jarak%20Data%20%28Penambangan%20Data%29/#1-mengukur-jarak-tipe-numerik","text":"Ada beberapa ukuran similaritas data ukuran jarak, diantaranya:","title":"1. Mengukur Jarak Tipe Numerik"},{"location":"Mengukur%20Jarak%20Data%20%28Penambangan%20Data%29/#a-minkowski-distance","text":"Kelompok Minkowski diantaranya adalah Euclidean distance dan Manhattan distance, Minkowski distance dinyatakan dengan: $$ \\begin{align} d _ { \\operatorname { min } } = ( \\sum _ { i = 1 } ^ { n } | x _ { i } - y _ { i } | ^ { m } ) ^ { \\frac { 1 } { m } } , m \\geq 1 \\end{align} $$","title":"a) Minkowski Distance"},{"location":"Mengukur%20Jarak%20Data%20%28Penambangan%20Data%29/#b-manhattan-distance","text":"Manhattan distance ialah kasus khusus dimana jarak dari minkoswski distance pada m= 1. Manhattan distance sensitif terhadap outlier. Jika ukuran ini digunakan dalam algoritma cleustering maka bentuk cleuster adalah hyper-rectangular. Ukuran ini dinyatakan dengan: $$ d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| $$","title":"b) Manhattan Distance"},{"location":"Mengukur%20Jarak%20Data%20%28Penambangan%20Data%29/#c-euclidean-distance","text":"Euclidean distance ialah metode pengukuran yang paling sering digunakan, euclidean distance menghitung akar dari kuadrat perbedaan dua buah atau lebih vektor. Metode ini dapat digunakan untuk mendeteksi tingkat ketidaksamaan citra dengan cara mengisi nilai vektor p dan q dengan nilai fitur citra yang akan dideteksi tingkat ketidaksamaannya. Euclidean distance memiliki kelemahan yaitu jika dua vektor data tidak memiliki nilai atribut yang sama, kemungkinan memiliki jarak yang lebih kecil daripada pasangan vektro data lainnya yang mengandung nilai atribut yang sama.","title":"c) Euclidean Distance"},{"location":"Mengukur%20Jarak%20Data%20%28Penambangan%20Data%29/#d-average-distance","text":"Dikarenakan kekurangan dari jarak euclidian distance diatas, maka rata-rata jarak adalah versi modifikasi dari jarak euclidian distance untuk memperbaiki hasil. Rata-rata jarak didefinisikan dengan: $$ d _ { a v e } = \\left ( \\frac { 1 } { n } \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } \\right) ^ { \\frac { 1 } { 2 } } $$","title":"d) Average Distance"},{"location":"Mengukur%20Jarak%20Data%20%28Penambangan%20Data%29/#e-weighted-euclidean-distance","text":"Jika berdasarkan tingkat penting dari masing-masing atribut ditentukan, maka weihted euclidean distance adalah modifikasi lain dari jarak euclidean distance yang dapat digunakan. Ukuran ini didefinisikan dengan: $$ d _ { w e } = \\left ( \\sum _ { i = 1 } ^ { n } w _ { i } ( x _ { i } - y _ { i } \\right) ^ { 2 } ) ^ { \\frac { 1 } { 2 } } $$","title":"e) Weighted Euclidean Distance"},{"location":"Mengukur%20Jarak%20Data%20%28Penambangan%20Data%29/#f-chord-distance","text":"Chord distance adalah salah satu ukuran modifikasi euclidean distance untuk mengatasi kekurangan dari euclidean distance. Jarak ini dapat juga dihitung dari data yang tidak dinormalisasi, Chord distance didefinisikan dengan: $$ d _ { w e } = \\left ( \\sum _ { i = 1 } ^ { n } w _ { i } ( x _ { i } - y _ { i } \\right) ^ { 2 } ) ^ { \\frac { 1 } { 2 } } $$","title":"f) Chord Distance"},{"location":"Mengukur%20Jarak%20Data%20%28Penambangan%20Data%29/#g-mahalanobis-distance","text":"Jarak mahalanobis yang teratur dapat digunakan untuk mengekstaksi hyperellipsoidal clusters. Jarak mahanalobis dapat mengurangi distorsi yang disebabkan oleh korelasi linier antar fitur dengan menerapkan transformasi pemutihan ke data atau dengan menggunakan kuadrat jarak mahalanobis. Mahalanobis distance didefinisikan dengan: $$ d _ { m a h } = \\sqrt { ( x - y ) S ^ { - 1 } ( x - y ) ^ { T } } $$","title":"g) Mahalanobis Distance"},{"location":"Mengukur%20Jarak%20Data%20%28Penambangan%20Data%29/#h-cosine-measure","text":"Ukuran cosine similarty lebih banyak digunakan dalam similaritas dokumen dan didefinisikan dengan: $$ Cosine(x,y)=\\frac { \\sum _ { i = 1 } ^ { n } x _ { i } y _ { i } } { | x | _ { 2 } | y | _ { 2 } } $$","title":"h) Cosine Measure"},{"location":"Mengukur%20Jarak%20Data%20%28Penambangan%20Data%29/#i-pearson-correlation","text":"Pearson correlation banyak digunakan pada data expresi gen. ukuran ini menghitung antara dua bentuk pola expresi gen. pearson corralatin didefinisikan dengan: $$ Pearson ( x , y ) = \\frac { \\sum _ { i = 1 } ^ { n } ( x _ { i } - \\mu _ { x } ) ( y _ { i } - \\mu _ { y } ) } { \\sqrt { \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } } \\sqrt { \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } } } $$","title":"i) Pearson Correlation"},{"location":"Mengukur%20Jarak%20Data%20%28Penambangan%20Data%29/#2mengukur-jarak-atribut-binary","text":"Similaritas dan desimilirity untuk objek yang dijelaskan oleh atribut biner simetris atau asimetris. Aatribut biner hanya memiliki dua status: 0 dan 1 Contoh atribut perokok menggambarkan seorang pasien, misalnya, 1 menunju kkan bahwa pasien merokok, sedangkan 0 menunjukkan pasien tidak merokok. Memperlakukan atribut biner sebagai atribut numerik tidak diperkennkan. Oleh karena itu,metode khusus untuk data biner diperlukan untuk membedakan komputasi.","title":"2.Mengukur Jarak Atribut Binary"},{"location":"Mengukur%20Jarak%20Data%20%28Penambangan%20Data%29/#dissimilarity-dan-similarity","text":"Rumus dissimilarity antara ii dan jj dan dinyatankan sebagai atribut biner simetris adalah: $$ \\begin{align} d(i,j) = \\frac {r+s}{q+r+s+t} \\end{align} $$ Rumusmedunissimilarity antara ii d n jj dan dinyatankan sebagai atribut binimetris adalah: $$ \\begin{align} d(i,j) = \\frac {r+s}{q+r+s} \\end{align} $$ Persamaan similarity Jaccard coefficient rumusnya adalah: $$ \\begin{align} sim(i,j) = \\frac {q}{q+r+s} = 1-d(i,j) \\end{align} $$","title":"Dissimilarity dan Similarity"},{"location":"Mengukur%20Jarak%20Data%20%28Penambangan%20Data%29/#3mengukur-jarak-menggunakan-catergorical","text":"","title":"3.Mengukur Jarak Menggunakan Catergorical"},{"location":"Mengukur%20Jarak%20Data%20%28Penambangan%20Data%29/#1-overlay-metric","text":"Untuk semua atribut bertipe nominal, ukuran jarak yang paling sederhana adalah Overlay Metric (OM) dinyatakan dengan $$ \\begin{align} d(x,y) = \\sum_{i=1}^n\\delta(a_i(x),a_i(y)) \\end{align} $$ Dimana nn adalah banyaknya atribut, ai(x)ai(x) dan ai(y)ai(y) adalah nilai atribut ke ii yaitu AiAi dari masing-masing objek xx dan yy, \u03b4(ai(x))(ai(y))\u03b4(ai(x))(ai(y)) adalah 0 jika ai(x)ai(x) = ai(y)ai(y) dan 1 jika sebaliknya.","title":"1. Overlay Metric"},{"location":"Mengukur%20Jarak%20Data%20%28Penambangan%20Data%29/#2-value-difference-metri","text":"VDM dikenalkan oleh Standfill and Waltz, versi sederhana dari VDM tanpa skema pembobotan didefinsisikan dengan: $$ \\begin{align} d(x,y) = \\sum_{i=1}^n\\sum_{c=1}^C|P(c|a_i(x)) - P(c|a_i(y)) \\end{align} $$ Dimana CC adalah banyaknya kelas, P(c|ai(x))P(c|ai(x)) adalah probabilitas bersyarat dimana kelas xx adalah cc dari atribut AiAi, yang memilki nilai ai(x)ai(x), P(c|ai(y))P(c|ai(y)) adalah probabilitas bersyarat dimana kelas y adalah c dengan atribut AiAi memiliki nilai ai(y).","title":"2. Value Difference Metri"},{"location":"Mengukur%20Jarak%20Data%20%28Penambangan%20Data%29/#3-minimum-risk-metric","text":"Ukuran ini dipresentasikan oleh Blanzieri and Ricci, berbeda dari SFM yaitu meminimumkan selisih antara kesalahan berhingga dan kesalahan asymtotic. MRM meminimumkan risk of misclassification yang didefinisikan dengan: $$ \\begin{align} d(x,y) = \\sum_{c=1}^C|P(c|x) (1 - P(c|y)) \\end{align} $$","title":"3. Minimum Risk Metric"},{"location":"Mengukur%20Jarak%20Data%20%28Penambangan%20Data%29/#4-mengukur-jarak-tipe-ordinal","text":"Perlakuan untuk atribut ordinal adalah cukup sama dengan atribut numerik ketika menghitung disimilarity antara objek. Misalkan ff adalah atribut-atribut dari atribut ordinak dan nn objek. Menghitung disimilarity terhadap ff fitur sebagai berikut: - Nilai ff untuk objek ke-ii adalah xifxif, dan ff memiliki MfMf status urutan, mewakili peringkat 1,...,Mf1,...,Mf ganti setiap XifXif dengan peringkatnya rif\u22081...MMfrif\u22081...MMf Karena setiap atribut ordinal dapat memiliki jumlah state yang berbeda, diperlukan untuk memetakan rentang setiap atribut ke [0,0, 1.0] sehingga setiap atribut memiliki bobot yang sama. Perl melakukan normalisasi data dengan mengganti peringkat rifrif dengan $$ \\begin{align} z_{if} = \\frac{r_{if} - 1}{M_f - 1} \\end{align} $$ Dissimilarity kemudian dihitung dengan menggunakan ukuran jarak seperti atribut numerik dengan data yang baru setelah ditransformasi zif","title":"4. Mengukur Jarak Tipe Ordinal"},{"location":"Mengukur%20Jarak%20Data%20%28Penambangan%20Data%29/#5-mengukur-jarak-tipe-campuran","text":"\\begin{align} d(i,j) = \\frac{\\sum_{f=1}^p\\delta_{ij}^{(f)} d_{ij}^{(f)}}{\\sum_{f=1}^pd_{ij}^{(f)}} \\end{align} \\begin{align} d(i,j) = \\frac{\\sum_{f=1}^p\\delta_{ij}^{(f)} d_{ij}^{(f)}}{\\sum_{f=1}^pd_{ij}^{(f)}} \\end{align} import pandas as pd from scipy import stats import numpy as np import seaborn as sns import matplotlib.pyplot as plt data = pd . read_csv ( \"Abalone.csv\" , delimiter = \";\" ) k = data . iloc [ 0 : 18 ] def jarak ( v1 , v2 ): return (( chordDist ( v1 , v2 , numerical ) + ordDist ( v1 , v2 , ordinal ) + categoricalDist ( v1 , v2 , categorical ) + binaryDist ( v1 , v2 , binary )) / 4 ) from IPython.display import HTML , display import tabulate table = [ [ \"Data\" ] + [ \"Jarak\" ] + [ \"Numeric\" ] + [ \"Ordinal\" ] + [ \"Categorical\" ] + [ \"Binary\" ], [ \"v1-v2\" ] + [ 0 ] + [ \" {:.2f} \" . format ( chordDist ( 0 , 1 , numerical ))] + [ \" {:.2f} \" . format ( ordDist ( 0 , 1 , ordinal ))] + [ categoricalDist ( 0 , 1 , categorical )] + [ binaryDist ( 0 , 1 , binary )], [ \"v1-v3\" ] + [ 0 ] + [ \" {:.2f} \" . format ( chordDist ( 0 , 2 , numerical ))] + [ \" {:.2f} \" . format ( ordDist ( 0 , 2 , ordinal ))] + [ categoricalDist ( 0 , 2 , categorical )] + [ binaryDist ( 0 , 1 , binary )], [ \"v2-v3\" ] + [ 0 ] + [ \" {:.2f} \" . format ( chordDist ( 1 , 2 , numerical ))] + [ \" {:.2f} \" . format ( ordDist ( 1 , 2 , ordinal ))] + [ categoricalDist ( 1 , 2 , categorical )] + [ binaryDist ( 0 , 1 , binary )], [ \"v3-v4\" ] + [ 0 ] + [ \" {:.2f} \" . format ( chordDist ( 2 , 3 , numerical ))] + [ \" {:.2f} \" . format ( ordDist ( 2 , 3 , ordinal ))] + [ categoricalDist ( 2 , 3 , categorical )] + [ binaryDist ( 0 , 1 , binary )], [ \"v4-v5\" ] + [ 0 ] + [ \" {:.2f} \" . format ( chordDist ( 3 , 4 , numerical ))] + [ \" {:.2f} \" . format ( ordDist ( 3 , 4 , ordinal ))] + [ categoricalDist ( 3 , 4 , categorical )] + [ binaryDist ( 0 , 1 , binary )], [ \"v5-v6\" ] + [ 0 ] + [ \" {:.2f} \" . format ( chordDist ( 4 , 5 , numerical ))] + [ \" {:.2f} \" . format ( ordDist ( 4 , 5 , ordinal ))] + [ categoricalDist ( 4 , 5 , categorical )] + [ binaryDist ( 0 , 1 , binary )], ] display ( HTML ( tabulate . tabulate ( table , tablefmt = 'html' )))","title":"5. Mengukur Jarak Tipe Campuran"},{"location":"Pengertian%20%28Andi%29/","text":"1. Mean(Rata-rata) \u00b6 Pengertian mean adalah nilai rata-rata dari beberapa buah data. Nilai mean dapat ditentukan dengan cara membagi jumlah data dengan banyaknya data. Rumus untuk mencari mean seperti berikut: $$ \\overline{x}=\\frac{\\sum_{i=1}^{N} x_{i}}{N}=\\frac{x_{1}+x_{2}+\\cdots+x_{N}}{N} $$ 2. Median \u00b6 pengertian median adalah suatu cara untuk menentukan letak tengah sebuah data setelah data disusun menurut urutan nilainya. Rumus untuk mencari median seperti berikut: M e=x_{i j}+\\left(\\frac{\\frac{n}{2}-f_{k i j}}{f_{i}}\\right) p M e=x_{i j}+\\left(\\frac{\\frac{n}{2}-f_{k i j}}{f_{i}}\\right) p 3. Modus \u00b6 Pengertian modus adalah nilai yang sering muncul. Untuk ingin melihat suatu hasil akhir dari modus maka harus menentukan kelas pada tabel dengan memilih frekuensi yang paling banyak. Rumus untuk mencari modus seperti berikut: \\text { mean }-\\text { mode } \\approx 3 \\times(\\text { mean }-\\text { median }) \\text { mean }-\\text { mode } \\approx 3 \\times(\\text { mean }-\\text { median }) 4. Standard deviasi \u00b6 Pengertian standard deviasi adalah nilai statistik yang digunakan untuk menentukan bagaimana sebaran data dalam sampel, dan seberapa dekat titik data individu ke mean atau rata-rata nilai sampel. Rumus untuk mencari standard deviasi sebagai berikut: \\sigma ^ { 2 } = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } ( x _ { i } - \\overline { x } ) ^ { 2 } = ( \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \\overline { x } ^ { 2 } \\sigma ^ { 2 } = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } ( x _ { i } - \\overline { x } ) ^ { 2 } = ( \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \\overline { x } ^ { 2 } 5. Varian \u00b6 Pengertian varian adalah ukuran seberapa jauh sebuah kumpulan bilangan tersebar, varian juga merupakan salah satu pendeskripsi dari sebuah distribusi probabilitas. Rumus untuk mencari devian sebagai berikut: \\sigma = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } ( x _ { i } - \\overline { x } ) ^ { 2 } = ( \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \\overline { x } ^ { 2 } \\sigma = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } ( x _ { i } - \\overline { x } ) ^ { 2 } = ( \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \\overline { x } ^ { 2 } 6. Skewness (Kemiringan) \u00b6 Pngertian skewness adalah derajat ketidaksimetrisan atau distribusi. Rumus untuk mencari skewness sebagai berikut: s k=\\frac{\\overline{X}-M o}{s} s k=\\frac{\\overline{X}-M o}{s} 7.Kuartil \u00b6 Pengertian kuartil adalah nilai-nilai yang membagi data yang telah diurutkan kedalam empat bagian yang nilainya sama besar, Kuartil terbagi menjadi 3 macam antara lain: a) Kuartil bawah (k1) b) kuartil tengah (k2) c)) Kuartil atas (k3) Rumus untuk memcri kuartil 1,2, dan 3 sebagai berikut: IQR=Q3\u2212Q1 IQR=Q3\u2212Q1 import pandas as pd from scipy import stats import numpy as np import seaborn as sns import matplotlib as plt data = pd . read_csv ( \"ANDIAJADOANG.csv\" , delimiter = \";\" ) cm = sns . light_palette ( \"gold\" , as_cmap = True ) data . style . background_gradient ( cmap = cm ) colum = data . columns . tolist () for x in colum : ds = [ x for x in data [ x ]] desc = data [ x ] . describe () array = [ x for x in desc ] print ( \"Detail kolom\" , x ) print ( \"rata-rata: \" , array [ 1 ]) print ( \"Median: \" , np . median ( np . array ( ds ))) print ( \"Modus: \" , stats . mode ( ds )) print ( \"Standard deviasi: \" , np . std ( ds )) print ( \"varian: \" , stats . variation ( ds )) print ( \"Skewness: \" , stats . skew ( ds )) print ( \"Quartil 1: \" , array [ 4 ]) print ( \"Quartil 2: \" , array [ 5 ]) print ( \"Quartil 3: \" , array [ 6 ]) sns . distplot ( data [ x ]) \u200b","title":"Statistika"},{"location":"Pengertian%20%28Andi%29/#1-meanrata-rata","text":"Pengertian mean adalah nilai rata-rata dari beberapa buah data. Nilai mean dapat ditentukan dengan cara membagi jumlah data dengan banyaknya data. Rumus untuk mencari mean seperti berikut: $$ \\overline{x}=\\frac{\\sum_{i=1}^{N} x_{i}}{N}=\\frac{x_{1}+x_{2}+\\cdots+x_{N}}{N} $$","title":"1. Mean(Rata-rata)"},{"location":"Pengertian%20%28Andi%29/#2-median","text":"pengertian median adalah suatu cara untuk menentukan letak tengah sebuah data setelah data disusun menurut urutan nilainya. Rumus untuk mencari median seperti berikut: M e=x_{i j}+\\left(\\frac{\\frac{n}{2}-f_{k i j}}{f_{i}}\\right) p M e=x_{i j}+\\left(\\frac{\\frac{n}{2}-f_{k i j}}{f_{i}}\\right) p","title":"2. Median"},{"location":"Pengertian%20%28Andi%29/#3-modus","text":"Pengertian modus adalah nilai yang sering muncul. Untuk ingin melihat suatu hasil akhir dari modus maka harus menentukan kelas pada tabel dengan memilih frekuensi yang paling banyak. Rumus untuk mencari modus seperti berikut: \\text { mean }-\\text { mode } \\approx 3 \\times(\\text { mean }-\\text { median }) \\text { mean }-\\text { mode } \\approx 3 \\times(\\text { mean }-\\text { median })","title":"3. Modus"},{"location":"Pengertian%20%28Andi%29/#4-standard-deviasi","text":"Pengertian standard deviasi adalah nilai statistik yang digunakan untuk menentukan bagaimana sebaran data dalam sampel, dan seberapa dekat titik data individu ke mean atau rata-rata nilai sampel. Rumus untuk mencari standard deviasi sebagai berikut: \\sigma ^ { 2 } = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } ( x _ { i } - \\overline { x } ) ^ { 2 } = ( \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \\overline { x } ^ { 2 } \\sigma ^ { 2 } = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } ( x _ { i } - \\overline { x } ) ^ { 2 } = ( \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \\overline { x } ^ { 2 }","title":"4. Standard deviasi"},{"location":"Pengertian%20%28Andi%29/#5-varian","text":"Pengertian varian adalah ukuran seberapa jauh sebuah kumpulan bilangan tersebar, varian juga merupakan salah satu pendeskripsi dari sebuah distribusi probabilitas. Rumus untuk mencari devian sebagai berikut: \\sigma = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } ( x _ { i } - \\overline { x } ) ^ { 2 } = ( \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \\overline { x } ^ { 2 } \\sigma = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } ( x _ { i } - \\overline { x } ) ^ { 2 } = ( \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \\overline { x } ^ { 2 }","title":"5. Varian"},{"location":"Pengertian%20%28Andi%29/#6-skewness-kemiringan","text":"Pngertian skewness adalah derajat ketidaksimetrisan atau distribusi. Rumus untuk mencari skewness sebagai berikut: s k=\\frac{\\overline{X}-M o}{s} s k=\\frac{\\overline{X}-M o}{s}","title":"6. Skewness (Kemiringan)"},{"location":"Pengertian%20%28Andi%29/#7kuartil","text":"Pengertian kuartil adalah nilai-nilai yang membagi data yang telah diurutkan kedalam empat bagian yang nilainya sama besar, Kuartil terbagi menjadi 3 macam antara lain: a) Kuartil bawah (k1) b) kuartil tengah (k2) c)) Kuartil atas (k3) Rumus untuk memcri kuartil 1,2, dan 3 sebagai berikut: IQR=Q3\u2212Q1 IQR=Q3\u2212Q1 import pandas as pd from scipy import stats import numpy as np import seaborn as sns import matplotlib as plt data = pd . read_csv ( \"ANDIAJADOANG.csv\" , delimiter = \";\" ) cm = sns . light_palette ( \"gold\" , as_cmap = True ) data . style . background_gradient ( cmap = cm ) colum = data . columns . tolist () for x in colum : ds = [ x for x in data [ x ]] desc = data [ x ] . describe () array = [ x for x in desc ] print ( \"Detail kolom\" , x ) print ( \"rata-rata: \" , array [ 1 ]) print ( \"Median: \" , np . median ( np . array ( ds ))) print ( \"Modus: \" , stats . mode ( ds )) print ( \"Standard deviasi: \" , np . std ( ds )) print ( \"varian: \" , stats . variation ( ds )) print ( \"Skewness: \" , stats . skew ( ds )) print ( \"Quartil 1: \" , array [ 4 ]) print ( \"Quartil 2: \" , array [ 5 ]) print ( \"Quartil 3: \" , array [ 6 ]) sns . distplot ( data [ x ]) \u200b","title":"7.Kuartil"},{"location":"Regresi%20Linier/","text":"Regresi Linier \u00b6 x1 x2 y 2 3 5 3 2 5 6 2 8 4 1 6 8 2 10 7 4 10 x1 x2 y x1y x2y x1x2 x1^2 x2^2 y^2 2 3 5 10 15 6 4 9 25 3 2 5 15 10 6 9 4 25 6 2 8 48 16 12 36 4 64 4 1 6 24 6 4 16 1 36 8 2 10 80 20 16 64 4 100 7 4 10 70 40 28 49 16 100 30 14 44 247 107 72 178 38 350 A= n . \\sum x_1y - (\\sum x_1)(\\sum y)= 6*247-30*44= 1482-1320= 162 A= n . \\sum x_1y - (\\sum x_1)(\\sum y)= 6*247-30*44= 1482-1320= 162 B= n . \\sum x_2^2 - (\\sum x_2)^2-(\\sum X_2)^2= 6*38-196= 228-196= 32 B= n . \\sum x_2^2 - (\\sum x_2)^2-(\\sum X_2)^2= 6*38-196= 228-196= 32 C= n . \\sum X_1 X_2- (\\sum X_1)(\\sum X_2)= 6*72-30*14= 432-420= 12 C= n . \\sum X_1 X_2- (\\sum X_1)(\\sum X_2)= 6*72-30*14= 432-420= 12 D= n . \\sum X_2Y- (\\sum X_2)(\\sum Y)= 6*107- 14*44= 642-616= 26 D= n . \\sum X_2Y- (\\sum X_2)(\\sum Y)= 6*107- 14*44= 642-616= 26 E= n. \\sum X_1^2-(\\sum X_1)^2 = 6*178-900=1068-900= 168 E= n. \\sum X_1^2-(\\sum X_1)^2 = 6*178-900=1068-900= 168 F= EB- C = 168*32-12=5376-12 =5354 F= EB- C = 168*32-12=5376-12 =5354 b1= \\frac{AB - CD}{F} = \\frac{(162)(32) - (12)(26)}{5354}= \\frac{5184- 312}{5354}= \\frac{4872}{5354}= 0,909 b1= \\frac{AB - CD}{F} = \\frac{(162)(32) - (12)(26)}{5354}= \\frac{5184- 312}{5354}= \\frac{4872}{5354}= 0,909 b2= \\frac{DE - AC}{F} = \\frac{(32)(168) - (162)(12)}{5354}= \\frac{5376 - 1644}{5354}= \\frac{3432}{5354}= 0,641 b2= \\frac{DE - AC}{F} = \\frac{(32)(168) - (162)(12)}{5354}= \\frac{5376 - 1644}{5354}= \\frac{3432}{5354}= 0,641 a= \\frac{\\sum y- b_1\\sum x_1- b_2\\sum x_2}{n} = \\frac{44-(0,909) (30)- (0,641)(14)}{6}= \\frac{7,756=}{6}= 1,292 $$ Hasil Akhir $$ {y}'= 1,292 + 0,909x_1 + 0,641 x_2 a= \\frac{\\sum y- b_1\\sum x_1- b_2\\sum x_2}{n} = \\frac{44-(0,909) (30)- (0,641)(14)}{6}= \\frac{7,756=}{6}= 1,292 $$ Hasil Akhir $$ {y}'= 1,292 + 0,909x_1 + 0,641 x_2 Pengecekan $$ x1 = 2 $$ $$ x2 = 8 $$ $$ y = a + b1x1 + b2x2 $$ import numpy as np from sklearn.linear_model import LinearRegression X = np . array ([[ 2 , 3 ], [ 3 , 2 ], [ 6 , 2 ], [ 4 , 1 ], [ 8 , 2 ], [ 7 , 4 ]]) y = np . array ([ 5 , 5 , 8 , 6 , 10 , 10 ]) X output: array ([[ 2 , 3 ], [ 3 , 2 ], [ 6 , 2 ], [ 4 , 1 ], [ 8 , 2 ], [ 7 , 4 ]]) reg = LinearRegression () . fit ( X , y ) reg . score ( X , y ) output 0.9932870888341911 a = reg . intercept_ a output 1.5963302752293584 b2 = reg . coef_ [ 1 ] b1 = reg . coef_ [ 0 ] x1 = 6 x2 = 2 b2 output 0.46330275229357804 y = b1 * x1 + b2 * x2 + a y output 16.0 reg . predict ( np . array ([[ 2 , 8 ]])) output array ([ 7.16513761 ])","title":"Regresi Linier Berganda"},{"location":"Regresi%20Linier/#regresi-linier","text":"x1 x2 y 2 3 5 3 2 5 6 2 8 4 1 6 8 2 10 7 4 10 x1 x2 y x1y x2y x1x2 x1^2 x2^2 y^2 2 3 5 10 15 6 4 9 25 3 2 5 15 10 6 9 4 25 6 2 8 48 16 12 36 4 64 4 1 6 24 6 4 16 1 36 8 2 10 80 20 16 64 4 100 7 4 10 70 40 28 49 16 100 30 14 44 247 107 72 178 38 350 A= n . \\sum x_1y - (\\sum x_1)(\\sum y)= 6*247-30*44= 1482-1320= 162 A= n . \\sum x_1y - (\\sum x_1)(\\sum y)= 6*247-30*44= 1482-1320= 162 B= n . \\sum x_2^2 - (\\sum x_2)^2-(\\sum X_2)^2= 6*38-196= 228-196= 32 B= n . \\sum x_2^2 - (\\sum x_2)^2-(\\sum X_2)^2= 6*38-196= 228-196= 32 C= n . \\sum X_1 X_2- (\\sum X_1)(\\sum X_2)= 6*72-30*14= 432-420= 12 C= n . \\sum X_1 X_2- (\\sum X_1)(\\sum X_2)= 6*72-30*14= 432-420= 12 D= n . \\sum X_2Y- (\\sum X_2)(\\sum Y)= 6*107- 14*44= 642-616= 26 D= n . \\sum X_2Y- (\\sum X_2)(\\sum Y)= 6*107- 14*44= 642-616= 26 E= n. \\sum X_1^2-(\\sum X_1)^2 = 6*178-900=1068-900= 168 E= n. \\sum X_1^2-(\\sum X_1)^2 = 6*178-900=1068-900= 168 F= EB- C = 168*32-12=5376-12 =5354 F= EB- C = 168*32-12=5376-12 =5354 b1= \\frac{AB - CD}{F} = \\frac{(162)(32) - (12)(26)}{5354}= \\frac{5184- 312}{5354}= \\frac{4872}{5354}= 0,909 b1= \\frac{AB - CD}{F} = \\frac{(162)(32) - (12)(26)}{5354}= \\frac{5184- 312}{5354}= \\frac{4872}{5354}= 0,909 b2= \\frac{DE - AC}{F} = \\frac{(32)(168) - (162)(12)}{5354}= \\frac{5376 - 1644}{5354}= \\frac{3432}{5354}= 0,641 b2= \\frac{DE - AC}{F} = \\frac{(32)(168) - (162)(12)}{5354}= \\frac{5376 - 1644}{5354}= \\frac{3432}{5354}= 0,641 a= \\frac{\\sum y- b_1\\sum x_1- b_2\\sum x_2}{n} = \\frac{44-(0,909) (30)- (0,641)(14)}{6}= \\frac{7,756=}{6}= 1,292 $$ Hasil Akhir $$ {y}'= 1,292 + 0,909x_1 + 0,641 x_2 a= \\frac{\\sum y- b_1\\sum x_1- b_2\\sum x_2}{n} = \\frac{44-(0,909) (30)- (0,641)(14)}{6}= \\frac{7,756=}{6}= 1,292 $$ Hasil Akhir $$ {y}'= 1,292 + 0,909x_1 + 0,641 x_2 Pengecekan $$ x1 = 2 $$ $$ x2 = 8 $$ $$ y = a + b1x1 + b2x2 $$ import numpy as np from sklearn.linear_model import LinearRegression X = np . array ([[ 2 , 3 ], [ 3 , 2 ], [ 6 , 2 ], [ 4 , 1 ], [ 8 , 2 ], [ 7 , 4 ]]) y = np . array ([ 5 , 5 , 8 , 6 , 10 , 10 ]) X output: array ([[ 2 , 3 ], [ 3 , 2 ], [ 6 , 2 ], [ 4 , 1 ], [ 8 , 2 ], [ 7 , 4 ]]) reg = LinearRegression () . fit ( X , y ) reg . score ( X , y ) output 0.9932870888341911 a = reg . intercept_ a output 1.5963302752293584 b2 = reg . coef_ [ 1 ] b1 = reg . coef_ [ 0 ] x1 = 6 x2 = 2 b2 output 0.46330275229357804 y = b1 * x1 + b2 * x2 + a y output 16.0 reg . predict ( np . array ([[ 2 , 8 ]])) output array ([ 7.16513761 ])","title":"Regresi Linier"}]}